# Ray分布式计算框架调研

监督学习:每一条数据伴随对应标签存在，监督学习目的是构建数据->标签的模型，最主流的模型是深度神经网络

Ray则是一种通用的集群计算框架，既支持模型的训练，又支持对环境的仿真或与环境的交互，还支持模型服务。Ray所面临的任务涵盖了从轻量级、无状态的计算任务（例如仿真）到长时间运行的、有状态的计算任务（例如训练）。为了满足这些任务的需求，Ray实现了一套统一的接口，这套接口既能表达**基于任务的并行计算**(task-parallel)，又能表达**基于行动器的并行计算**(actor-based)。前者使得Ray能高效地、动态地对仿真、高维状态输入处理（如图像、视频）和错误恢复等任务进行负载均衡，后者行动器的设计使得Ray能有效地支持有状态的计算，例如模型训练、与客户端共享可变状态（如参数服务器）。Ray在一个具有高可扩展性和容错性的动态执行引擎上实现了对任务和行动器的抽象。

### Ray编程模型

**Ray编程模型**是指Ray框架基于任务和行动器这两个重要需求所向用户提供的一套API及其编程范式。下表展示了Ray提供的核心API。

任务是指在无状态的工作器中执行的远程函数。远程函数被调用时会立即返回一个future对象，而真正的返回值可以通过ray.get(<future对象>)的方式来获取。**这样的编程模型既允许用户编写并行计算代码，同时又提醒用户要关注数据之间的依赖性。**

### Ray计算模型

* Ray产生的背景:由于AI和大数据的快速发展，对于应用和硬件能力的要求提出了更高的挑战。

* Ray的特点:分布式异步调用,内存调度,Pandas/Numpy的分布式支持,支持python,整体性能出众

* 基本的软件框架

  Ray的架构由应用层和系统层组成，其中应用层实现了Ray的API,作为前端供用户使用，而系统层则作为后端来保障Ray的高扩展性和容错性，整体框架如下

![img](https://pic2.zhimg.com/80/v2-689ccf19063644dc49b077914b8d5b41_1440w.webp)

GCS 作为集中的服务端，是 Worker 之间传递消息的纽带。每个 Server 都有一个共用的 Object Store，也就是用 Apache Arrow/Plasma 构建的内存数据。 Local Scheduler 是 Server 内部的调度（单机调度），同时通过 GCS 来和其他 Server 上的 Worker 通信。Object Store 之间也有通信，作用是传递 Worker 之间的数据。

Local Scheduler，即Raylet，本地调度核心

**调度过程：任务创建后，首先向本地调度器提交任务，大多数情况下任务将在本地被调度。若没有资源，局部调度器会向全局调度器传递任务，向GCS传递任务信息，然后全局调度器会选择等待时间最短的、有足够资源的节点来执行任务**

![img](https://pic1.zhimg.com/80/v2-2580040deb0f1524fd3905919b271cd4_1440w.webp)

任务定义、提交、远程提交过程:0.定义远程函数1.提交任务2.提交任务到全局3.检查对象表4.执行全局调度5.检查任务输入6.查询缺失输入7.对象复制8.执行局部调度9.访问对象存储器

获取任务执行结果过程:1.调教get请求2.注册回调函数3.任务执行完毕4.将对象同步到GCS 5.出发回调函数6.执行回调函数7.返回用户程序

### 其他分布式计算框架

* Dask:Dask的核心时弥补python在数据科学中的不足，主要是性能上。python单机的能力不够支持大数据集的快速计算。**Dask的目标是为了弥补Python在数据科学上的不足，而Ray的出发点是为了加速机器学习的调优和训练的速度**。数据科学和机器学习基础以python为核心,两者都以对Python Pandas/Numpy为框架基础，但也略有不同。

  

### 参考文献

[Ray分布式计算框架](https://arxiv.org/pdf/1712.05889.pdf)



